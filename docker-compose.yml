version: "3.11"
services:
#  litellm:
#    image: ghcr.io/berriai/litellm:main-latest
#    volumes:
#      - ./config.yaml:/app/config.yaml
#    command:
#      - "--config=/app/config.yaml"
#    ports:
#      - "4000:4000"
#    env_file:
#      - .env

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "8080:8080"
    environment:
      - 'OPENAI_API_BASE_URL=http://host.docker.internal:4000/v1'
      - 'WEBUI_AUTH=false'
      - 'ENABLE_LITELLM=true'
      - 'LITELLM_PROXY_PORT=4000'
      - 'LITELLM_PROXY_HOST=127.0.0.1'
    restart: unless-stopped
